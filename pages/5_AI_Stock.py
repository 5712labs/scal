import streamlit as st
import pandas as pd
# import numpy as np
from pykrx import stock
import matplotlib.pyplot as plt
from prophet import Prophet
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import yfinance as yf
from pandas_datareader import data as pdr
from components import convert
import feedparser
from googleapiclient.discovery import build

st.set_page_config(page_title="AI Stock Search Engine", page_icon="ðŸ", layout="wide")

if convert.check_auth() == False:
    st.stop()

st.title("AI ì£¼ê°€ ì˜ˆì¸¡")

clear_button = st.sidebar.button("Clear Cache", key="clear", type="secondary")
if clear_button:
    st.cache_data.clear()

search_date = st.sidebar.date_input("ê¸°ì¤€ì¼ìž", datetime.today())
today_button = st.sidebar.button("Today", key="today")
if today_button:
    search_date = datetime.today()

@st.cache_data
def load_data():
    stocks_KQ = pd.DataFrame({'ì¢…ëª©ì½”ë“œ':stock.get_market_ticker_list(market="KOSPI")})
    stocks_KQ['ì¢…ëª©ëª…'] = stocks_KQ['ì¢…ëª©ì½”ë“œ'].map(lambda x: stock.get_market_ticker_name(x))
    stocks_KQ['ì½”ë“œ'] = stocks_KQ['ì¢…ëª©ì½”ë“œ'] + '.KS'
    
    stocks_KS = pd.DataFrame({'ì¢…ëª©ì½”ë“œ':stock.get_market_ticker_list(market="KOSDAQ")})
    stocks_KS['ì¢…ëª©ëª…'] = stocks_KS['ì¢…ëª©ì½”ë“œ'].map(lambda x: stock.get_market_ticker_name(x))
    stocks_KS['ì½”ë“œ'] = stocks_KS['ì¢…ëª©ì½”ë“œ'] + '.KQ'

    stocks_KQKS = pd.concat([stocks_KQ, stocks_KS])
    
    # ì „ì²´ ì¢…ëª©ì˜ ì—…ì¢… 
    krx_url = 'https://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13'
    fdr_datastk_data = pd.read_html(krx_url, header=0, encoding='cp949')[0]  # í•´ë‹¹ siteì—ì„œ table ì¶”ì¶œ ë° headerëŠ” ê°€ìž¥ ì²«ë²ˆì§¸ í–‰
    stk_data = fdr_datastk_data[['ì¢…ëª©ì½”ë“œ', 'ì—…ì¢…', 'ì£¼ìš”ì œí’ˆ']].copy()  # 9ê°œì˜ ì—´ ì¤‘ 'íšŒì‚¬ëª…', 'ì¢…ëª©ì½”ë“œ' ë§Œ ì¶”ì¶œí•˜ì—¬ dataframe ì™„ì„±
    # ì¢…ëª©ì½”ë“œê°€ ëª¨ë‘ 6ìžë¦¬ë¡œ ì´ë£¨ì–´ì ¸ìžˆì§€ë§Œ í˜¹ì‹œ ëª¨ë¥´ë‹ˆ, 6ìžë¦¬ ë¯¸ë§Œ ì½”ë“œëŠ” ì•žì— 0ì„ ì±„ì›Œë„£ì–´ 6ìžë¦¬ ìˆ«ìží…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    stk_data['ì¢…ëª©ì½”ë“œ'] = stk_data['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6) #6ìžë¦¬ë¡œ ë³€í™˜
    stock_list = pd.merge(stocks_KQKS, stk_data, on='ì¢…ëª©ì½”ë“œ', how='left')
    # ì „ì²´ ì¢…ëª©ì˜ íŽ€ë”ë©˜íƒˆ ì§€í‘œ ê°€ì ¸ì˜¤ê¸°
    # íŽ€ë”ë©˜íƒˆ ì§€í‘œëŠ” PER, PBR, EPS, BPS, DIV, DPSë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    currdate = search_date.strftime('%Y-%m-%d')
    stock_fud = pd.DataFrame(stock.get_market_fundamental_by_ticker(date=currdate, market="ALL"))
    stock_fud = stock_fud.reset_index()
    stock_fud.rename(columns={'í‹°ì»¤':'ì¢…ëª©ì½”ë“œ'}, inplace=True)

    # result = pd.merge(stock_list, stock_fud, left_on='ì¢…ëª©ì½”ë“œ', right_on='ì¢…ëª©ì½”ë“œ', how='left')
    result = pd.merge(stock_list, stock_fud, on='ì¢…ëª©ì½”ë“œ', how='left')
    
    stock_price = stock.get_market_ohlcv_by_ticker(date=currdate, market="ALL")
    stock_price = stock_price.reset_index()
    stock_price.rename(columns={'í‹°ì»¤':'ì¢…ëª©ì½”ë“œ'}, inplace=True)
    # result1 = pd.merge(result, stock_price, left_on='ì¢…ëª©ì½”ë“œ', right_on='ì¢…ëª©ì½”ë“œ', how='left')
    result1 = pd.merge(result, stock_price, on='ì¢…ëª©ì½”ë“œ', how='left')
    #ì½”ë„¥ìŠ¤ ì œê±°
    result1.dropna(subset=['ì¢…ëª©ëª…'], how='any', axis=0, inplace=True)
    
    # result1 = result1.replace([0], np.nan)    # 0ê°’ì„ NaNìœ¼ë¡œ ë³€ê²½
    # result1 = result1.dropna(axis=0)      # NaNì„ ê°€ì§„ í–‰ ì œê±°
    # result1 = result1.sort_values(by=['PER'], ascending=True)
    result1 = result1.sort_values(by=['ê±°ëž˜ëŸ‰'], ascending=False)
    result1['ë‚´ìž¬ê°€ì¹˜'] = (result1['BPS'] + (result1['EPS']) * 10) / 2
    result1['ë‚´ìž¬ê°€ì¹˜/ì¢…ê°€'] = (result1['ë‚´ìž¬ê°€ì¹˜'] / result1['ì¢…ê°€'])
    # st.write('result1')
    # st.write(result1.head())
    # result1.sort_values(by=['ê±°ëž˜ëŸ‰'], ascending=False, inplace=)
    return result1

analy = load_data()
with st.expander(f'{search_date} ì¢…ëª©ë¦¬ìŠ¤íŠ¸ {analy.shape} ', expanded=False):
    st.write(analy)

# ê²€ìƒ‰ ê¸°ëŠ¥
text_search = st.text_input("AI Stock Search Engine", value="ëŒ€ìš°ê±´ì„¤", placeholder='ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª…, ì—…ì¢…, ì£¼ìš”ì œí’ˆìœ¼ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”')
m1 = analy["ì¢…ëª©ì½”ë“œ"].str.contains(text_search)
m2 = analy["ì¢…ëª©ëª…"].str.contains(text_search)
m3 = analy["ì—…ì¢…"].str.contains(text_search)
m4 = analy["ì£¼ìš”ì œí’ˆ"].str.contains(text_search)

df_search = analy[m1 | m2 | m3 | m4]

anal_sel = st.empty()

anal_tube = st.container() # ìœ íŠœë¸Œ ê²€ìƒ‰
anal_news = st.container() # êµ¬ê¸€ ë‰´ìŠ¤

# ì£¼ê°€ì˜ˆì¸¡
col1, col2, col3 = st.columns(3)
with col1:
    anal_03t = st.empty()
    anal_03y= st.empty()
with col2:
    anal_rst = st.empty()
    anal_rsi = st.empty()
with col3:
    anal_10t = st.empty()
    anal_10y = st.empty()

anal_info = st.empty() # íšŒì‚¬ê°œìš”

def analys(stock_name, stock_code):
    selected_analy = analy[analy['ì½”ë“œ'] == stock_code]
    # ì„ íƒ ì¢…ëª© ì¢…ê°€ì •ë³´
    anal_sel.write(selected_analy)

    try:
        # ìœ íŠœë¸Œ ê²€ìƒ‰
        youtube = build("youtube", "v3",developerKey=st.secrets["api_youtube"])
        search_response = youtube.search().list(
        q = stock_name,
        order = "relevance",
        part = "snippet",
        maxResults = 10
        ).execute()

        def info_to_dict(videoId, title, description, url):
            result = {
                "videoId": videoId,
                "title": title,
                "description": description,
                "url": url
            }
            return result

        result_json = {}
        idx =0
        for item in search_response['items']:
            if item['id']['kind'] == 'youtube#video':
                result_json[idx] = info_to_dict(item['id']['videoId'], item['snippet']['title'], item['snippet']['description'], item['snippet']['thumbnails']['medium']['url'])
                idx += 1

        with anal_tube:
            # st.write(result_json)
            gpt_feed_col = 5
            cols = st.columns(gpt_feed_col)
            for idx, item in enumerate(search_response['items']):
                if item['id']['kind'] == 'youtube#video':
                    # result_json[idx] = info_to_dict(item['id']['videoId'], item['snippet']['title'], item['snippet']['description'], item['snippet']['thumbnails']['medium']['url'])
                    # idx += 1
                    colsnum = ( idx % gpt_feed_col )
                    with cols[colsnum]:
                        st.image(item['snippet']['thumbnails']['medium']['url'])
    except Exception as e:
        st.write('ê´€ë ¨ ìœ íŠœë¸Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.', e)
    
    try:
        # êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰
        # í˜„ìž¬ ë‚ ì§œì—ì„œ 1ì¼ì„ ë¹¼ì„œ '1d' í˜•íƒœì˜ ë¬¸ìžì—´ì„ ìƒì„± (ì–´ì œ ë‚ ì§œ)
        date_since = (datetime.now() - timedelta(3)).strftime('%Y-%m-%d')
        rss_url = f'https://news.google.com/rss/search?q={stock_name}+after:{date_since}&hl=ko&gl=KR&ceid=KR:ko'

        feeds = feedparser.parse(rss_url)
        # pubDateë¥¼ datetime ê°ì²´ë¡œ íŒŒì‹±í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
        def parse_pubdate(entry):
            return datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %Z')

        # ê° í•­ëª©ì˜ pubDateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤ (ìµœì‹  ë‚ ì§œê°€ ë¨¼ì € ì˜¤ë„ë¡).
        sorted_feeds = sorted(feeds.entries, key=parse_pubdate, reverse=True)

        cols = anal_news.columns(5)
        # for idx, feed in enumerate(sorted_feeds[:10]): 
        for idx, feed in enumerate(sorted_feeds): 
            pub_date = parse_pubdate(feed)
            colsnum = ( idx % 5 )
            with cols[colsnum]:
                st.link_button(feed.title + f' {pub_date}', feed.link)
    except Exception as e:
        st.write('ê´€ë ¨ ë‰´ìŠ¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.', e)

    start_date = datetime(2010,3,1)
    end_date = datetime.today()
    yf.pdr_override()
    stock = pdr.get_data_yahoo(str(stock_code), start_date, end_date)
    get_stock_data = yf.Ticker(stock_code)
    if 'longBusinessSummary' in get_stock_data.info:
        anal_info.write(get_stock_data.info['longBusinessSummary'])
    stock_trunc = stock[:-30]

    df = pd.DataFrame({"ds":stock_trunc.index, "y":stock_trunc["Close"]})
    df.reset_index(inplace=True)
    del df ["Date"]
    m = Prophet(yearly_seasonality=True, daily_seasonality=True)
    m.fit(df)

    future = m.make_future_dataframe(periods=90, freq='D')
    forecast = m.predict(future)

    anal_10t.write(""" ### 10ë…„ ì¶”ì„¸ """)

    fig2 = plt.figure(figsize=(8,3))
    plt.plot(stock.index, stock["Close"], label="real")
    plt.plot(forecast["ds"], forecast["yhat"], label="forecast")
    anal_10y.pyplot(fig2)

    # anal_03t.write(""" ### í–¥í›„ 3ê°œì›” ì˜ˆì¸¡ """)
    anal_03t.write(f"### {stock_name} í–¥í›„ 3ê°œì›” ì˜ˆì¸¡")
    idx_num = forecast.index[(forecast['ds'] >= datetime.today())]
    forecast = forecast[idx_num[0] - 120:] #ë§ˆì§€ë§‰ 10ê°œ?
    stock = stock[idx_num[0] - 120:]

    # ì˜ˆì¸¡ ê·¸ëž˜í”„
    m.plot(forecast)
    m.plot_components(forecast)

    fig2 = plt.figure(figsize=(8,3))
    last_date = stock['Close'][-1:].index[0]
    last_dt = last_date.strftime('%Y-%m-%d')
    last_Close = round(stock['Close'][-1:][0])

    plt.plot(stock.index, stock["Close"], label="real")
    plt.annotate(f'Stock \n {last_Close} \n {last_dt}', 
                xy=(last_date, last_Close),
                xytext=(last_date + relativedelta(weeks=1), last_Close),
                weight='bold',
                arrowprops=dict(arrowstyle="->",
                                connectionstyle="arc3,rad=0.2"),
                )
    fore = forecast[['ds', 'yhat']][-1:]
    fore_date = fore.iloc[0]['ds']
    fore_dt = fore_date.strftime('%Y-%m-%d')
    fore_Close = round(fore.iloc[0]['yhat'])
    plt.plot(forecast["ds"], forecast["yhat"], label="forecast")
    plt.annotate(f'AI \n {fore_Close} \n {fore_dt}', 
                xy=(fore_date, fore_Close),
                xytext=(fore_date - relativedelta(weeks=16), fore_Close),
                weight='bold',
                arrowprops=dict(arrowstyle="->",
                                connectionstyle="arc3,rad=0.2"),
                )
    anal_03y.pyplot(fig2)

    anal_rst.write(""" ### ìµœê·¼ 3ê°œì›” RSI """)
    # RSI ì˜ˆì¸¡ Plotting
    rsi_data = convert.calculate_rsi(stock)

    fig3 = plt.figure(figsize=(14, 7))
    plt.subplot(2, 1, 1)
    plt.plot(rsi_data.index, rsi_data['Close'], label='Close Price')
    plt.title('Close Price & RSI Graph')

    plt.subplot(2, 1, 2)
    plt.plot(rsi_data.index, rsi_data['RSI'], label='RSI', color='orange')
    plt.axhline(0, linestyle='--', alpha=0.5, color='black')
    plt.axhline(20, linestyle='--', alpha=0.5, color='red')
    plt.axhline(30, linestyle='--', alpha=0.5, color='red')
    plt.axhline(70, linestyle='--', alpha=0.5, color='blue')
    plt.axhline(80, linestyle='--', alpha=0.5, color='blue')
    plt.axhline(100, linestyle='--', alpha=0.5, color='black')
    anal_rsi.pyplot(fig3)

expander_stocks = st.container()
with expander_stocks:
    N_cards_per_row = 8
    if text_search:
        for n_row, row in df_search.reset_index().iterrows():
            i = n_row%N_cards_per_row
            if i==0:
                st.write("---")
                cols = st.columns(N_cards_per_row, gap="small")
            # draw the card
            with cols[n_row%N_cards_per_row]:
                search = st.button(f"**{row['ì¢…ëª©ëª…']}**", type="primary", key=f"{row['ì½”ë“œ']}")
                st.markdown(f"****{row['ì—…ì¢…']}****")
                st.caption(f"{row['ì£¼ìš”ì œí’ˆ']}")
                if search:
                    with st.spinner('Wait for it...'):
                        analys(f"{row['ì¢…ëª©ëª…']}", f"{row['ì½”ë“œ']}")
st.stop()