import streamlit as st
import json
import pyrfc
import pandas as pd
from datetime import datetime
from dateutil.relativedelta import relativedelta
from pandas.tseries.offsets import MonthEnd, MonthBegin
import altair as alt
from components import convert

st.set_page_config(page_title="AI DW", page_icon="ğŸ", layout='centered')
if convert.check_auth() == False:
    st.stop()

# st.header(f"ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡ ğŸ‘‹")

open_json = "./db/sap_connect_dcd.json"
f = open(open_json)
connect = json.load(f)

## í…Œì´ë¸” READ : í…Œì´ë¸”ëª…-ZAACFRM
with pyrfc.Connection(**connect) as conn:
    fields = ['SITPRT', 'CONTO']

    if open_json == "./db/sap_connect_dcd.json":
        today = datetime.today() - relativedelta(year=1)
    today = today.strftime('%Y%m%d')
    rst01 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "ZTYF91", OPTIONS = [{'TEXT' : "BUKRS = '1000'"}, {'TEXT' : f"AND CONTO > '{today}'"}, {'TEXT' : f"AND CONTO NE '99991231'"}], FIELDS = fields, DELIMITER = "|")
    
    fields = ['SITPRT', 'SEQ', 'APPROVEDATE', 'PLNRATE', 'DGAMT', 'SUM_COST', 'WAERS']
    rst02 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "ZFGT0510",  OPTIONS = [{'TEXT' : "BUKRS = '1000'"}], FIELDS = fields, DELIMITER = "|")

    fields = ['PRCTR', 'KTEXT']
    opt01 = "SPRAS = '3'"
    options = [{'TEXT' : opt01}]
    rst03 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "CEPCT", OPTIONS = options, FIELDS = fields, DELIMITER = "|")

data = []
columns = []
for line in rst01["DATA"]:
    raw_data = line["WA"].strip().split("|")
    data.append(raw_data)
for line in rst01["FIELDS"]:
    columns.append(line['FIELDTEXT'])
rst01_df = pd.DataFrame(data)
rst01_df.columns = columns
rst01_df.columns = ['í˜„ì¥ì½”ë“œ', 'ì¢…ë£Œì¼']
rst01_df['ì¢…ë£Œì¼'] = pd.to_datetime(rst01_df['ì¢…ë£Œì¼'])
rst01_df['í˜„ì¥ì½”ë“œ'] = rst01_df['í˜„ì¥ì½”ë“œ'].str.replace(" ", "")

data = []
columns = []
for line in rst03["DATA"]:
    raw_data = line["WA"].strip().split("|")
    data.append(raw_data)
rst03_df = pd.DataFrame(data)
rst03_df.columns = ['í˜„ì¥ì½”ë“œ', 'í˜„ì¥ëª…']
rst03_df['í˜„ì¥ì½”ë“œ'] = rst03_df['í˜„ì¥ì½”ë“œ'].str.replace(" ", "")

data = []
for line in rst02["DATA"]:
    raw_data = line["WA"].strip().split("|")
    data.append(raw_data)
rst02_df = pd.DataFrame(data)
rst02_df.columns = ['í˜„ì¥ì½”ë“œ', 'ìˆœë²ˆ', 'ê²°ì¬ì¼', 'ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨', 'ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡', 'ê³„(ì‚¬ì—…ì˜ˆì •ì›ê°€)', 'í†µí™”']
rst02_df['ê²°ì¬ì¼'] = pd.to_datetime(rst02_df['ê²°ì¬ì¼'])
rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'] = rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'].str.replace('*','10')
rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'] = rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'].astype('float64')
rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] = rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'].str.replace('*','10')
rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] = rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'].astype('float64')
rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] = rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] * 100
rst02_df['ê³„(ì‚¬ì—…ì˜ˆì •ì›ê°€)'] = rst02_df['ê³„(ì‚¬ì—…ì˜ˆì •ì›ê°€)'].astype('float64')
rst02_df['í˜„ì¥ì½”ë“œ'] = rst02_df['í˜„ì¥ì½”ë“œ'].str.replace(" ", "")
rst02_df.drop(rst02_df[(rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] == 0)].index, inplace=True)

rst01_df = pd.merge(rst01_df, rst03_df, how='left', on=None)
merge_df = pd.merge(left=rst02_df, right=rst01_df, how='inner', on='í˜„ì¥ì½”ë“œ')
merge_df.reset_index(drop=True, inplace=True)
merge_df['ê²°ì¬ì¼'] = merge_df['ê²°ì¬ì¼'] + MonthEnd()

merge_df.sort_values(by=['í˜„ì¥ì½”ë“œ', 'ê²°ì¬ì¼'], inplace=True)
merge_df = merge_df.reset_index(drop=True)

layout_01 = st.container()
st.write(""" ### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ë¶„í¬""")
layout_02 = st.container()
st.write(""" ### ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡ (ë‹¨ìœ„: ì²œì–µ)""")
layout_03 = st.container()
st.write(""" ### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ëˆ„ì ë³€ë™ìœ¨ """)
layout_04 = st.container()

change_eco_df = pd.DataFrame() # ë³€ë™ë¥ 
last_df = pd.DataFrame() # ë³€ë™ë¥ 
grouped_df = merge_df.groupby('í˜„ì¥ì½”ë“œ')
for key, data in grouped_df :
    sort_data = data.sort_values(by=['ê²°ì¬ì¼'], ascending=True)
    sort_data['dpc'] = (sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨/sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨.shift(1)-1)*100
    sort_data['ë³€ë™ë¥ '] = round(sort_data.dpc.cumsum(), 2)
    
    change_eco_df = pd.concat([change_eco_df, sort_data])

    last3_df = pd.DataFrame(change_eco_df.iloc[len(change_eco_df.index)-1]).T
    last_df = pd.concat([last_df, last3_df])

change_eco_df = change_eco_df.fillna(0)

last_df.drop(last_df[(last_df['ë³€ë™ë¥ '] == 0)].index, inplace=True)
last_df.dropna(inplace=True)
last_df.sort_values(by=['ë³€ë™ë¥ '], ascending=False, inplace=True)

##########################################################################
### ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡ (ë‹¨ìœ„: ì²œì–µ) ################################################
##########################################################################
bar_chart = alt.Chart(last_df).mark_bar().encode(
    y = alt.X("ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡", bin=alt.Bin(step=100000000000)), #ì²œì–µ
    x = 'count(*):Q',
)
layout_03.altair_chart(bar_chart, use_container_width=True)

##########################################################################
### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ë¶„í¬ #######################################################
##########################################################################
bar_chart = alt.Chart(last_df).mark_bar().encode(
    alt.X("ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨:Q", bin=alt.Bin(step=5)), #ë°±ì–µ
    y='count()',
)
layout_02.altair_chart(bar_chart, use_container_width=True)

##########################################################################
### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ëˆ„ì ë³€ë™ìœ¨ ###################################################
##########################################################################
last_df = last_df.fillna(0)
dpc_zero = last_df[(last_df['ë³€ë™ë¥ '] < 10) & (last_df['ë³€ë™ë¥ '] > -10)]['í˜„ì¥ì½”ë“œ']
last_df = last_df[~last_df['í˜„ì¥ì½”ë“œ'].isin(dpc_zero)]
change_eco_df = change_eco_df[change_eco_df['í˜„ì¥ì½”ë“œ'].isin(last_df['í˜„ì¥ì½”ë“œ'])]
merge_df = change_eco_df

df = change_eco_df
min_date = pd.to_datetime(df['ê²°ì¬ì¼'].min())
earliest_dates = df.groupby('í˜„ì¥ì½”ë“œ')['ê²°ì¬ì¼'].min().reset_index() # ê° symbolë³„ë¡œ ê°€ì¥ ì´ë¥¸ Date ì°¾ê¸°
new_rows = pd.DataFrame(columns=merge_df.columns) # Preparing DataFrame to collect new rows
for _, row in earliest_dates.iterrows():
    symbol_data = df[df['í˜„ì¥ì½”ë“œ'] == row['í˜„ì¥ì½”ë“œ']]
    earliest_row = symbol_data[symbol_data['ê²°ì¬ì¼'] == row['ê²°ì¬ì¼']].iloc[0].copy()
    earliest_row['ê²°ì¬ì¼'] = min_date
    new_rows = new_rows.append(earliest_row, ignore_index=True)
merge_df = pd.concat([merge_df, new_rows], axis=0)

last_df = pd.DataFrame() # ë³€ë™ë¥ 
grouped_df = merge_df.groupby('í˜„ì¥ì½”ë“œ')
for key, data in grouped_df :
    sort_data = data.sort_values(by=['ê²°ì¬ì¼'], ascending=True)
    sort_data['dpc'] = (sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨/sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨.shift(1)-1)*100
    sort_data['ë³€ë™ë¥ '] = round(sort_data.dpc.cumsum(), 2)
    
    change_eco_df = pd.concat([change_eco_df, sort_data])

    last3_df = pd.DataFrame(change_eco_df.iloc[len(change_eco_df.index)-1]).T
    last_df = pd.concat([last_df, last3_df])

change_eco_df = change_eco_df.fillna(0)
last_df.sort_values(by=['ë³€ë™ë¥ '], ascending=False, inplace=True)
last_wr = last_df.sort_values('ë³€ë™ë¥ ', ascending=False)[['í˜„ì¥ì½”ë“œ','í˜„ì¥ëª…','ë³€ë™ë¥ ','ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨','ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡','ì¢…ë£Œì¼']].reset_index(drop=True)
st.write(last_wr)

lines = alt.Chart(change_eco_df).mark_line().encode(
    x = alt.X('ê²°ì¬ì¼:T', title=''),
    # y = alt.Y('ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨:Q', title=''),
    y = alt.Y('ë³€ë™ë¥ :Q', title=''),
    color = alt.Color('í˜„ì¥ëª…:N', title='ì§€í‘œ', legend=alt.Legend(
        orient='bottom', 
        direction='horizontal',
        titleAnchor='end'))
)

text_data = last_df
text_data.reset_index(drop=True, inplace=True)
text_data3 = pd.DataFrame(text_data.loc[0].T)
text_data3 = text_data[:1].copy()
if len(text_data.index) > 1:
    text_data3.loc[1] = text_data.loc[len(text_data.index)-1]
if len(text_data.index) > 2:
    text_data3.loc[2] = text_data.loc[round(len(text_data.index)/2)]

labels = alt.Chart(text_data3).mark_text(
    # point=True,
    fontWeight=600,
    fontSize=15,
    # color='white',
    align='left',
    dx=15,
    dy=-8
).encode(
    x = alt.X('ê²°ì¬ì¼:T', title=''),
    # y = alt.Y('rate:Q', title=rate_text),
    y = alt.Y('ë³€ë™ë¥ :Q', title=''),
    # y = 'rate:Q',
    text=alt.Text('ë³€ë™ë¥ :Q', format='.1f'),
    # text=alt.TextValue(text_data3['í˜„ì¥ëª…'][0] + text_data3['í˜„ì¥ëª…'][0]),
    color = alt.Color('í˜„ì¥ëª…:N', title='')
)

labels2 = alt.Chart(text_data3).mark_text(
    # point=True,
    fontWeight=600,
    fontSize=15,
    # color='white',
    align='left',
    dx=15,
    dy=10
).encode(
    x = alt.X('ê²°ì¬ì¼:T', title=''),
    # y = alt.Y('rate:Q', title=rate_text),
    y = alt.Y('ë³€ë™ë¥ :Q', title=''),
    # y = 'rate:Q',
    text=alt.Text('í˜„ì¥ëª…:N'),
    # text=alt.TextValue(text_data3['í˜„ì¥ëª…'][0] + text_data3['í˜„ì¥ëª…'][0]),
    color = alt.Color('í˜„ì¥ëª…:N', title='')
)

columns = sorted(change_eco_df.í˜„ì¥ëª….unique())
selection = alt.selection_point(
    fields=['ê²°ì¬ì¼'], nearest=True, on='mouseover', empty=False, clear='mouseout'
)
points = lines.mark_point().transform_filter(selection)

base = alt.Chart(change_eco_df).encode(x='ê²°ì¬ì¼:T')
rule = base.transform_pivot(
    'í˜„ì¥ëª…', value='ë³€ë™ë¥ ', groupby=['ê²°ì¬ì¼']
    ).mark_rule().encode(
    opacity=alt.condition(selection, alt.value(0.3), alt.value(0)),
    tooltip=[alt.Tooltip(c, type='quantitative') for c in columns]
).add_params(selection)

layout_04.altair_chart(lines + rule + points + labels + labels2, 
                use_container_width=True)