import streamlit as st
import json
import pyrfc
import pandas as pd
from datetime import datetime
from dateutil.relativedelta import relativedelta
from pandas.tseries.offsets import MonthEnd, MonthBegin
import altair as alt
from components import convert

st.set_page_config(page_title="AI DW", page_icon="ğŸ", layout='wide')
if convert.check_auth() == False:
    st.stop()

st.write(""" ### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ëˆ„ì ë³€ë™ìœ¨ """)
layout_01 = st.container()
layout_04 = st.container()
st.write(""" ### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ë¶„í¬""")
layout_02 = st.container()
st.write(""" ### ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡ (ë‹¨ìœ„: ì²œì–µ)""")
layout_03 = st.container()

open_json = "./db/sap_connect_dcp.json"
f = open(open_json)
connect = json.load(f)

## í…Œì´ë¸” READ : í…Œì´ë¸”ëª…-ZAACFRM
with pyrfc.Connection(**connect) as conn:
    fields = ['SITPRT', 'CONFROM', 'CONTO']

    if open_json == "./db/sap_connect_dcp.json":
        today = datetime.today()
    else :
        today = datetime.today() - relativedelta(month=1)
    rst01 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "ZTYF91", OPTIONS = [{'TEXT' : "BUKRS EQ '1000'"}, {'TEXT' : f"AND CONTO > '{today}'"}, {'TEXT' : f"AND CONTO NE '99991231'"}], FIELDS = fields, DELIMITER = "|")
    
    # fields = ['SITPRT', 'SEQ', 'APPROVEDATE', 'PLNRATE', 'DGAMT', 'SUM_COST', 'WAERS']
    fields = ['SITPRT', 'APPROVEDATE', 'PLNRATE', 'DGAMT', 'SUM_COST', 'WAERS']
    rst02 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "ZFGT0510",  OPTIONS = [{'TEXT' : "BUKRS EQ '1000'"}], FIELDS = fields, DELIMITER = "|")

    fields = ['PRCTR', 'KTEXT']
    opt01 = "SPRAS = '3'"
    # opt02 = "AND KTEXT = 'ê³µì •ì„¤ê³„íŒ€'"
    # opt02 = "AND KTEXT LIKE '%ë¶ˆê´‘ë™%'"
    opt02 = ''
    options = [{'TEXT' : opt01}, {'TEXT' : opt02}]
    # rst03 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "CEPCT", OPTIONS = options, FIELDS = fields, DELIMITER = "|")
    rst03 = conn.call("RFC_READ_TABLE", QUERY_TABLE = "CEPCT", OPTIONS = options, FIELDS = fields, DELIMITER = "|")


data = []
columns = []
for line in rst01["DATA"]:
    raw_data = line["WA"].strip().split("|")
    data.append(raw_data)
for line in rst01["FIELDS"]:
    columns.append(line['FIELDTEXT'])
rst01_df = pd.DataFrame(data)
rst01_df.columns = columns
rst01_df.columns = ['í˜„ì¥ì½”ë“œ', 'ì‹œì‘ì¼', 'ì¢…ë£Œì¼']
rst01_df['ì‹œì‘ì¼'] = pd.to_datetime(rst01_df['ì‹œì‘ì¼'])
rst01_df['ì¢…ë£Œì¼'] = pd.to_datetime(rst01_df['ì¢…ë£Œì¼'])
rst01_df['í˜„ì¥ì½”ë“œ'] = rst01_df['í˜„ì¥ì½”ë“œ'].str.replace(" ", "")

data = []
columns = []
for line in rst03["DATA"]:
    raw_data = line["WA"].strip().split("|")
    data.append(raw_data)
rst03_df = pd.DataFrame(data)
rst03_df.columns = ['í˜„ì¥ì½”ë“œ', 'í˜„ì¥ëª…']
rst03_df['í˜„ì¥ì½”ë“œ'] = rst03_df['í˜„ì¥ì½”ë“œ'].str.replace(" ", "")

data = []
for line in rst02["DATA"]:
    raw_data = line["WA"].strip().split("|")
    data.append(raw_data)
rst02_df = pd.DataFrame(data)
rst02_df.columns = ['í˜„ì¥ì½”ë“œ', 'ê²°ì¬ì¼', 'ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨', 'ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡', 'ê³„(ì‚¬ì—…ì˜ˆì •ì›ê°€)', 'í†µí™”']
rst02_df['ê²°ì¬ì¼'] = pd.to_datetime(rst02_df['ê²°ì¬ì¼'])
rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'] = rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'].str.replace('*','10')
rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'] = rst02_df['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'].astype('float64')
rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] = rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'].str.replace('*','10') #12ê°€ ë ìˆ˜ë„ ìˆìŒ
rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] = rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'].astype('float64')
rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] = rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] * 100
rst02_df['ê³„(ì‚¬ì—…ì˜ˆì •ì›ê°€)'] = rst02_df['ê³„(ì‚¬ì—…ì˜ˆì •ì›ê°€)'].astype('float64')
rst02_df['í˜„ì¥ì½”ë“œ'] = rst02_df['í˜„ì¥ì½”ë“œ'].str.replace(" ", "")
rst02_df.drop(rst02_df[(rst02_df['ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡'] == 0)].index, inplace=True)

# # rst01_df = pd.merge(rst01_df, rst03_df, how='left', on=None)
# rst01_df = pd.merge(rst03_df, rst01_df, how='inner', on='í˜„ì¥ì½”ë“œ')
# # merge_df = pd.merge(left=rst02_df, right=rst01_df, how='inner', on='í˜„ì¥ì½”ë“œ')
# merge_df = pd.merge(left=rst01_df, right=rst02_df, how='inner', on='í˜„ì¥ì½”ë“œ')

merge_df = pd.merge(left=rst03_df, right=rst02_df, how='inner', on='í˜„ì¥ì½”ë“œ')
merge_df = pd.merge(left=merge_df, right=rst01_df, how='inner', on='í˜„ì¥ì½”ë“œ')
merge_df.sort_values(by=['í˜„ì¥ì½”ë“œ', 'ê²°ì¬ì¼'], inplace=True)
merge_df.reset_index(drop=True, inplace=True)

last_df = merge_df.loc[merge_df.groupby(['í˜„ì¥ì½”ë“œ'])['ê²°ì¬ì¼'].idxmax()]

##########################################################################
### ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡ (ë‹¨ìœ„: ì²œì–µ) ################################################
##########################################################################
bar_chart = alt.Chart(last_df).mark_bar().encode(
    y = alt.X("ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡", bin=alt.Bin(step=100000000000)), #ì²œì–µ
    x = 'count(*):Q',
)
# layout_03.altair_chart(bar_chart, use_container_width=True)

##########################################################################
### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ë¶„í¬ #######################################################
##########################################################################
bar_chart = alt.Chart(last_df).mark_bar().encode(
    alt.X("ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨:Q", bin=alt.Bin(step=5)), #ë°±ì–µ
    y='count()',
)
# layout_02.altair_chart(bar_chart, use_container_width=True)

##########################################################################
### ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨ ëˆ„ì ë³€ë™ìœ¨ ###################################################
##########################################################################

# change_eco_df = pd.DataFrame() # ë³€ë™ë¥ 
# last_df = pd.DataFrame() # ë³€ë™ë¥ 
# grouped_df = merge_df.groupby('í˜„ì¥ì½”ë“œ')
# for key, data in grouped_df :
#     sort_data = data.sort_values(by=['ê²°ì¬ì¼'], ascending=True)
#     sort_data['dpc'] = (sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨/sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨.shift(1)-1)*100
#     sort_data['ë³€ë™ë¥ '] = round(sort_data.dpc.cumsum(), 2)
    
#     change_eco_df = pd.concat([change_eco_df, sort_data])

#     last3_df = pd.DataFrame(change_eco_df.iloc[len(change_eco_df.index)-1]).T
#     last_df = pd.concat([last_df, last3_df])

# change_eco_df = pd.DataFrame()  # ë³€ë™ë¥ 
# grouped_df = merge_df.groupby('í˜„ì¥ì½”ë“œ')
# for _, data in grouped_df:
#     sort_data = data.sort_values(by=['ê²°ì¬ì¼'])
#     sort_data['dpc'] = (sort_data['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'].pct_change()) * 100
#     sort_data['ë³€ë™ë¥ '] = round(sort_data['dpc'].cumsum(), 2)
#     change_eco_df = pd.concat([change_eco_df, sort_data])

# change_eco_df = change_eco_df.fillna(0)

# last_df = last_df.fillna(0)
# dpc_zero = last_df[(last_df['ë³€ë™ë¥ '] < 10) & (last_df['ë³€ë™ë¥ '] > -10)]['í˜„ì¥ì½”ë“œ']
# last_df = last_df[~last_df['í˜„ì¥ì½”ë“œ'].isin(dpc_zero)]
# change_eco_df = change_eco_df[change_eco_df['í˜„ì¥ì½”ë“œ'].isin(last_df['í˜„ì¥ì½”ë“œ'])]
# merge_df = change_eco_df

# df = change_eco_df
# min_date = pd.to_datetime(df['ê²°ì¬ì¼'].min())
# earliest_dates = df.groupby('í˜„ì¥ì½”ë“œ')['ê²°ì¬ì¼'].min().reset_index() # ê° symbolë³„ë¡œ ê°€ì¥ ì´ë¥¸ Date ì°¾ê¸°
# new_rows = pd.DataFrame(columns=merge_df.columns) # Preparing DataFrame to collect new rows
# for _, row in earliest_dates.iterrows():
#     symbol_data = df[df['í˜„ì¥ì½”ë“œ'] == row['í˜„ì¥ì½”ë“œ']]
#     earliest_row = symbol_data[symbol_data['ê²°ì¬ì¼'] == row['ê²°ì¬ì¼']].iloc[0].copy()
#     earliest_row['ê²°ì¬ì¼'] = min_date
#     new_rows = new_rows.append(earliest_row, ignore_index=True)
# merge_df = pd.concat([merge_df, new_rows], axis=0)

# merge_df = merge_df[merge_df['í˜„ì¥ì½”ë“œ'] == 'HLDQA']

merge_df['ê²°ì¬ì¼'] = merge_df['ê²°ì¬ì¼'] + MonthEnd()

# min_df = merge_df.loc[merge_df.groupby(['í˜„ì¥ì½”ë“œ'])['ê²°ì¬ì¼'].idxmin()]
# min_df['ê²°ì¬ì¼'] = merge_df['ê²°ì¬ì¼'].min()
# max_df = merge_df.loc[merge_df.groupby(['í˜„ì¥ì½”ë“œ'])['ê²°ì¬ì¼'].idxmax()]
# max_df['ê²°ì¬ì¼'] = merge_df['ê²°ì¬ì¼'].max()
# merge_df = pd.concat((merge_df, min_df, max_df))
# merge_df = merge_df.drop_duplicates()
# merge_df.sort_values(by=['í˜„ì¥ì½”ë“œ', 'ê²°ì¬ì¼'], inplace=True)
# merge_df = merge_df.reset_index(drop=True)

option = layout_01.selectbox(
    '',
    ('ì „ì²´ ê¸°ê°„', 'ìµœê·¼ 3ê°œì›”', 'ìµœê·¼ 6ê°œì›”', 'ìµœê·¼ 12ê°œì›”'))
if option == 'ì „ì²´ ê¸°ê°„':
    period = datetime.today() - relativedelta(years=30)
elif option == 'ìµœê·¼ 3ê°œì›”':
    period = datetime.today() - relativedelta(months=6)
elif option == 'ìµœê·¼ 6ê°œì›”':
    period = datetime.today() - relativedelta(months=3)
elif option == 'ìµœê·¼ 12ê°œì›”':
    period = datetime.today() - relativedelta(years=1)

merge_df = merge_df[merge_df['ê²°ì¬ì¼'] > period]

min_df = merge_df.loc[merge_df.groupby(['í˜„ì¥ì½”ë“œ'])['ê²°ì¬ì¼'].idxmin()]
min_df['ê²°ì¬ì¼'] = merge_df['ê²°ì¬ì¼'].min()
max_df = merge_df.loc[merge_df.groupby(['í˜„ì¥ì½”ë“œ'])['ê²°ì¬ì¼'].idxmax()]
max_df['ê²°ì¬ì¼'] = merge_df['ê²°ì¬ì¼'].max()
merge_df = pd.concat((merge_df, min_df, max_df))
merge_df = merge_df.drop_duplicates()


merge_df.sort_values(by=['í˜„ì¥ì½”ë“œ', 'ê²°ì¬ì¼'], inplace=True)
merge_df = merge_df.reset_index(drop=True)

change_eco_df = pd.DataFrame()  # ë³€ë™ë¥ 
grouped_df = merge_df.groupby('í˜„ì¥ì½”ë“œ')
for key, data in grouped_df :
    sort_data = data.sort_values(by=['ê²°ì¬ì¼'], ascending=True)
    # sort_data['dpc'] = (sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨/sort_data.ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨.shift(1)-1)*100
    sort_data['dpc'] = (sort_data['ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨'].pct_change()) * 100
    sort_data['ë³€ë™ë¥ '] = round(sort_data.dpc.cumsum(), 2)
    change_eco_df = pd.concat([change_eco_df, sort_data])

last_df = change_eco_df.loc[change_eco_df.groupby(['í˜„ì¥ì½”ë“œ'])['ê²°ì¬ì¼'].idxmax()]
last_df = last_df.fillna(0)
dpc_zero = last_df[(last_df['ë³€ë™ë¥ '] < 5) & (last_df['ë³€ë™ë¥ '] > -5)]['í˜„ì¥ì½”ë“œ']
last_df = last_df[~last_df['í˜„ì¥ì½”ë“œ'].isin(dpc_zero)]
change_eco_df = change_eco_df[change_eco_df['í˜„ì¥ì½”ë“œ'].isin(last_df['í˜„ì¥ì½”ë“œ'])]
# merge_df = change_eco_df

change_eco_df = change_eco_df.fillna(0)
last_df = last_df.fillna(0)
last_df.sort_values(by=['ë³€ë™ë¥ '], ascending=False, inplace=True)
last_wr = last_df.sort_values('ë³€ë™ë¥ ', ascending=False)[['í˜„ì¥ì½”ë“œ','í˜„ì¥ëª…','ë³€ë™ë¥ ','ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨','ì¤€ê³µì˜ˆì •ë„ê¸‰ì•¡','ì¢…ë£Œì¼']].reset_index(drop=True)
st.write(last_wr)

lines = alt.Chart(change_eco_df).mark_line().encode(
    x = alt.X('ê²°ì¬ì¼:T', title=''),
    # y = alt.Y('ì¤€ê³µì˜ˆì •ì›ê°€ìœ¨:Q', title=''),
    y = alt.Y('ë³€ë™ë¥ :Q', title=''),
    color = alt.Color('í˜„ì¥ëª…:N', title='ì§€í‘œ', legend=alt.Legend(
        orient='bottom', 
        direction='horizontal',
        titleAnchor='end'))
)

text_data = last_df
text_data.reset_index(drop=True, inplace=True)
text_data3 = pd.DataFrame(text_data.loc[0].T)
text_data3 = text_data[:1].copy()
if len(text_data.index) > 1:
    text_data3.loc[1] = text_data.loc[len(text_data.index)-1]
if len(text_data.index) > 2:
    text_data3.loc[2] = text_data.loc[round(len(text_data.index)/2)]

labels = alt.Chart(text_data3).mark_text(
    # point=True,
    fontWeight=600,
    fontSize=15,
    # color='white',
    align='left',
    dx=15,
    dy=-8
).encode(
    x = alt.X('ê²°ì¬ì¼:T', title=''),
    # y = alt.Y('rate:Q', title=rate_text),
    y = alt.Y('ë³€ë™ë¥ :Q', title=''),
    # y = 'rate:Q',
    text=alt.Text('ë³€ë™ë¥ :Q', format='.1f'),
    # text=alt.TextValue(text_data3['í˜„ì¥ëª…'][0] + text_data3['í˜„ì¥ëª…'][0]),
    color = alt.Color('í˜„ì¥ëª…:N', title='')
)

labels2 = alt.Chart(text_data3).mark_text(
    # point=True,
    fontWeight=600,
    fontSize=15,
    # color='white',
    align='left',
    dx=15,
    dy=10
).encode(
    x = alt.X('ê²°ì¬ì¼:T', title=''),
    # y = alt.Y('rate:Q', title=rate_text),
    y = alt.Y('ë³€ë™ë¥ :Q', title=''),
    # y = 'rate:Q',
    text=alt.Text('í˜„ì¥ëª…:N'),
    # text=alt.TextValue(text_data3['í˜„ì¥ëª…'][0] + text_data3['í˜„ì¥ëª…'][0]),
    color = alt.Color('í˜„ì¥ëª…:N', title='')
)

columns = sorted(change_eco_df.í˜„ì¥ëª….unique())
selection = alt.selection_point(
    fields=['ê²°ì¬ì¼'], nearest=True, on='mouseover', empty=False, clear='mouseout'
)
points = lines.mark_point().transform_filter(selection)

base = alt.Chart(change_eco_df).encode(x='ê²°ì¬ì¼:T')
rule = base.transform_pivot(
    'í˜„ì¥ëª…', value='ë³€ë™ë¥ ', groupby=['ê²°ì¬ì¼']
    ).mark_rule().encode(
    opacity=alt.condition(selection, alt.value(0.3), alt.value(0)),
    tooltip=[alt.Tooltip(c, type='quantitative') for c in columns]
).add_params(selection)

layout_04.altair_chart(lines + rule + points + labels + labels2, 
                use_container_width=True)