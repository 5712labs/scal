import streamlit as st
import openai
from components import convert
import tiktoken
import feedparser
from datetime import datetime, timedelta
from googleapiclient.discovery import build
from components.db_manager import DBManagerNews

st.set_page_config(page_title="AI NEWS", page_icon="ğŸ", layout='centered', initial_sidebar_state='auto')

if convert.check_auth() == False:
    st.stop()

st.title("AI NEWS ğŸŒ")

db = DBManagerNews()

clear_button = st.sidebar.button("ìƒˆ ëŒ€í™” ì‹œì‘", type="primary", key="clear_newss")
if clear_button:
    st.session_state['nmessages'] = [
        {"role": "system", "content": "You are a helpful assistant.", "hide": False}
    ]

get_news_list = ['í•œêµ­', 'ë¯¸êµ­', 'ìºë‚˜ë‹¤', 'ë‚˜ì´ì§€ë¦¬ì•„', 'ë² íŠ¸ë‚¨', 'ì¼ë³¸', 'ëª¨ë¡œì½”', 'UAE', 'ì¸ë„ë„¤ì‹œì•„', 'ë§ë ˆì´ì‹œì•„', 'ì§ë°”ë¸Œì›¨', 'íŒŒí‚¤ìŠ¤íƒ„', 'ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„', 'ì—í‹°ì˜¤í”¼ì•„'] #, 'ë¦¬ë¹„ì•„',  'ì´ë¼í¬', 'ìº„ë³´ë””ì•„', 'ì˜¤ë§Œ', 'íˆ¬ë¥´í¬']
# get_news_range = st.sidebar.multiselect("êµ­ê°€", get_news_list, get_news_list)
get_news_range = st.multiselect("êµ­ê°€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”", get_news_list, ['í•œêµ­', 'ë² íŠ¸ë‚¨', 'ë‚˜ì´ì§€ë¦¬ì•„', 'ë¯¸êµ­'])
# gpt_feed_max = st.number_input('êµ­ê°€ë³„ ìµœì‹ ë‰´ìŠ¤ ê°¯ìˆ˜', value=3, min_value=1, max_value=100)
gpt_feed_max = st.slider('ìµœì‹ ë‰´ìŠ¤ ê°¯ìˆ˜ë¥¼ ììœ ë¡­ê²Œ ë³€ê²½í•˜ì„¸ìš” ', 0, 50, 5)

def parse_pubdate(entry):
    # published_dt = datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %Z')
    published_dt = datetime.strptime(entry, '%a, %d %b %Y %H:%M:%S %Z')
    formatted_str = published_dt.strftime('%Y. %m. %d')
    return formatted_str


def get_news_feeds(get_news_range, gpt_feed_max):

    gpt_feeds = '''

    #ì…ë ¥ë¬¸
    '''

    gpt_feed_col = 3

    # sorted_all_feeds = get_news_feed(get_news_range)
    sorted_all_feeds = []
    for range in get_news_range:
        news_feeds = db.get_conutry_news(range)
        for idx, feed in enumerate(news_feeds):
            feed = feed + (idx + 1, )
            sorted_all_feeds.append(feed)
        
    cols = st.columns(gpt_feed_col)

    for idx, feed in enumerate(sorted_all_feeds): 
        if gpt_feed_max < feed[11]:
            continue
        # deepl = translator.translate_text(feed['title'], target_lang='KO')
        pub_date = parse_pubdate(feed[9])
        colsnum = ( idx % gpt_feed_col )
        with cols[colsnum]:
            # st.link_button(feed.nation + ' ' + feed.title + f' {pub_date}', feed.link)
            # st.link_button(feed[1] + ' ' + feed[3] + '\n\n[GPTë²ˆì—­] ' + feed[5] + '\n\n[DEEPLë²ˆì—­] ' + feed[4] + f' {pub_date}', feed[8])
            nation = feed[1]
            conutry = feed[2]
            title = feed[3]
            deepl_ko = feed[4]
            chatgpt_ko = feed[5]
            papago_ko = feed[6]
            google_ko = feed[7]
            link = feed[8]
            published = feed[9]
            updated_at = feed[10]
            if conutry == 'í•œêµ­':
                st.link_button(nation + f' {pub_date}' + '\n\n' + title, link)
            else:
                st.link_button(nation + f' {pub_date}' + '\n\n[ì›ë¬¸] ' + title + '\n\n[GPTë²ˆì—­] ' + chatgpt_ko + '\n\n[DEEPLë²ˆì—­] ' + deepl_ko, link)
            
        # gpt_feeds += f'[êµ­ê°€: {feed.conutry}] [ê¸°ì‚¬] {feed.title} \n\n'
    gpt_feeds += '''
    #ì¶œë ¥í˜•ì‹
    [í•œêµ­] - ê¸ì • : ê¸ì • ë˜ëŠ” ë¶€ì •ê´€ë ¨ ë‹¨ì–´ 3ê°œ
    1. ê¸°ì‚¬
    2. ê¸°ì‚¬
    [ë¯¸êµ­] - ë¶€ì • : ê¸ì • ë˜ëŠ” ë¶€ì •ê´€ë ¨ ë‹¨ì–´ 3ê°œ
    1. ê¸°ì‚¬
    2. ê¸°ì‚¬
        '''
    return gpt_feeds

gpt_feeds = get_news_feeds(get_news_range, gpt_feed_max)

# @st.cache_data
def get_tube_feed():
    youtube = build("youtube", "v3",developerKey=st.secrets["api_youtube"])
    search_response = youtube.search().list(
    q = 'ê±´ì„¤',
    order = "relevance",
    part = "snippet",
    maxResults = 9
    ).execute()

    def info_to_dict(videoId, title, description, url):
        result = {
            "videoId": videoId,
            "title": title,
            "description": description,
            "url": url
        }
        return result

    result_json = {}
    idx =0
    for item in search_response['items']:
        if item['id']['kind'] == 'youtube#video':
            result_json[idx] = info_to_dict(item['id']['videoId'], item['snippet']['title'], item['snippet']['description'], item['snippet']['thumbnails']['medium']['url'])
            idx += 1
    # st.write(result_json)
    
    gpt_feed_col = 3
    cols = st.columns(gpt_feed_col)
    for idx, item in enumerate(search_response['items']):
        if item['id']['kind'] == 'youtube#video':
            # result_json[idx] = info_to_dict(item['id']['videoId'], item['snippet']['title'], item['snippet']['description'], item['snippet']['thumbnails']['medium']['url'])
            # idx += 1
            colsnum = ( idx % gpt_feed_col )
            with cols[colsnum]:
                st.image(item['snippet']['thumbnails']['medium']['url'])

get_tube_feed()


if "nmessages" not in st.session_state:
    st.session_state.nmessages = []

for message in st.session_state.nmessages:
    if message["hide"] == False:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

prompt = st.chat_input("Say something")

prompt1_button = st.button("GPT ìš”ì•½í•˜ê¸°", type="primary", key="prompt1")
if prompt1_button:
    gpt_feed = '''
    #ëª…ë ¹ë¬¸
    ì•„ë˜ì˜ ì œì•½ì¡°ê±´ê³¼ ì…ë ¥ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ
    [êµ­ê°€]ë³„ë¡œ êµ¬ë¶„í•´ì„œ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”
    ìš”ì•½ í›„ì—ëŠ” 'ê¸ì •' ë˜ëŠ” 'ë¶€ì •' ë‘˜ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”
    ì¶”ê°€ ì„¤ëª…ì—†ì´ ê¸ì • ë˜ëŠ” ë¶€ì •ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ 3ê°œë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”
    
    #ì œì•½ì¡°ê±´
    ìš”ì ì„ ëª…í™•íˆ í•œë‹¤
    ë¬¸ì¥ì€ ê°„ê²°í•˜ê²Œ ì•Œê¸° ì‰½ê²Œ ì“´ë‹¤

    '''
    gpt_feeds = gpt_feed + gpt_feeds

    prompt = gpt_feeds
    st.session_state['nmessages'] = [
        {"role": "user", "content": gpt_feeds, 'hide': True}
    ]

prompt2_button = st.button("ê±´ì„¤ ë‰´ìŠ¤ ìš”ì•½í•˜ê¸°", type="primary", key="prompt2")
if prompt2_button:

    gpt_feed = '''
    #ëª…ë ¹ë¬¸
    ì•„ë˜ì˜ ì œì•½ì¡°ê±´ê³¼ ì…ë ¥ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ
    [êµ­ê°€]ë³„ë¡œ ê±´ì„¤ ê´€ë ¨ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”
    ìš”ì•½ í›„ì—ëŠ” 'ê¸ì •' ë˜ëŠ” 'ë¶€ì •' ë‘˜ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”
    ì¶”ê°€ ì„¤ëª…ì—†ì´ ê¸ì • ë˜ëŠ” ë¶€ì •ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ 3ê°œë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”
    
    #ì œì•½ì¡°ê±´
    ê±´ì„¤ ê´€ë ¨ ê¸°ì‚¬ë§Œ ì¶œë ¥í•œë‹¤
    ê±´ì„¤ ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´ ê±´ì„¤ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤ ë¼ê³ ë§Œ ëŒ€ë‹µí•œë‹¤
    ê±´ì„¤ ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ëŠ” êµ­ê°€ëŠ” ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤
    ìš”ì ì„ ëª…í™•íˆ í•œë‹¤
    ë¬¸ì¥ì€ ê°„ê²°í•˜ê²Œ ì•Œê¸° ì‰½ê²Œ ì“´ë‹¤
    í•œêµ­ì–´ë¡œ ì¶œë ¥í•œë‹¤

    '''
    gpt_feeds = gpt_feed + gpt_feeds
    prompt = gpt_feeds

if prompt:
    if prompt1_button or prompt2_button :
        # ê¸°ì¡´ ìœ ì € ë©”ì‹œì§€ëŠ” ì‚­ì œí•˜ê¸°
        st.session_state.nmessages = [
            message for message in st.session_state.nmessages
            if message["role"] != "user" or message["hide"] != True
        ]
        st.session_state.nmessages.append({"role": "user", "content": prompt, "hide": True})

    else:
        st.session_state.nmessages.append({"role": "user", "content": prompt, "hide": False})
        with st.chat_message("user"):
            st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for response in openai.chat.completions.create(
            model=st.session_state["openai_model"],
            # model = 'gpt-3.5-turbo-1106',
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.nmessages
            ],
            stream=True,
        ):
            for chunk in response.choices:
                if chunk.finish_reason == 'stop':
                    break
                full_response += chunk.delta.content
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.nmessages.append({"role": "assistant", "content": full_response, "hide": False})

tokenizer = tiktoken.get_encoding("cl100k_base")
tokenizer = tiktoken.encoding_for_model("gpt-4-1106-preview") # gpt-3.5-turbo

with st.expander('í”„ë¡¬í”„íŠ¸ ë³´ê¸°', expanded=False):
    st.write(st.session_state.nmessages)

message_cnt = 0
token_size = 0
for message in st.session_state['nmessages']:
    if message['role'] == 'system':
        continue
    encoding_result = tokenizer.encode(message['content'])
    token_size = token_size + len(encoding_result)
    message_cnt = message_cnt + 1

if token_size != 0:
    st.caption(f"{message_cnt} ê°œì˜ ëŒ€í™”ì—ì„œ {token_size} í† í°ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ì˜ˆìƒë¹„ìš©ì€ {round(token_size * 0.00001, 2)}$ ì…ë‹ˆë‹¤")
